---
layout: post
title: Tornado Peril
landing-title: 'Blog'
description: A rapid, sudden shift...
image: assets/images/pic12.png
show_tile: true
nav-menu: true
---

In this blog post, we'll showcase our approach to the tornado peril and how it is applied using data engineering and how we apply it in a business setting.

We use geographic data to give us high granular actuarial statistics to quanitfy financial risk across an portfolio of assets.

For the example, we'll be looking at a portfolio of real estate assets.



![image info](/assets/images/pic12.jpg)



### **Tornado Statistics for Underwriting**
***`annual_probabilities`*** **is a measure of how often tornado events occur in a particular hexagon, on average.**
 * It is calculated by *dividing the total number of tornado events in a hexagon by the sum of the years difference between each event*.
 * ***For example***, suppose we have a hexagon with 5 tornado events, and the years difference between each event is 1, 2, 3, 4, and 5 years, respectively. 
 * The sum of the years difference is 1+2+3+4+5=15. 
 * The average frequency of tornado events in this hexagon would be 5/15=0.33 events per year, on average.

### **Expected Loss**

The **Annual Expected Loss (AEL)** equation in the insurance industry is a statistical measure used to ***estimate the amount of money an insurer is likely to pay out on claims over the course of a year***. It is calculated by multiplying the Probability of Loss (PoL) by the Expected Loss Amount (ELA).

Mathematically, the equation for Annual Expected Loss is:
 * **AEL = PoL x ELA**



where:
 * **PoL** is the ***probability of a loss*** occurring within a given period of time (usually one year)
 * **ELA** is the ***expected loss amount*** for a single loss event
To calculate the Annual Expected Loss, an insurer will typically use ***historical data*** to estimate the PoL and ELA for a particular type of insurance policy  (Rejda & McNamara, 2021). 
 * The **insurer** may also factor in other variables, such as the level of risk associated with a particular policy, to refine their estimate of the AEL. By estimating the AEL, insurers can ***better understand the potential financial impact of insuring a particular risk*** and set appropriate premium rates to cover their expected losses (Rejda & McNamara, 2021).


Other calculations to be made...
 * Value at Risk (VaR)

```
import numpy as np

# Assuming a normal distribution, we will use the scipy library for VaR calculation
from scipy.stats import norm

# Confidence level (e.g., 95%)
confidence_level = 0.95

# Calculate portfolio loss distribution (sum of expected losses)
portfolio_loss_distribution = df['expected_loss'].sum()

# Calculate standard deviation of the portfolio loss distribution
# You can use historical data or other methods to estimate the standard deviation
portfolio_loss_std_dev = np.std(df['expected_loss'])

# Calculate VaR at the specified confidence level
VaR = norm.ppf(confidence_level, loc=portfolio_loss_distribution, scale=portfolio_loss_std_dev)

print("Value at Risk (VaR):", VaR)
```

 * Tail Value at Risk (TVaR)

```
# Calculate TVaR at the specified confidence level
# First, we need to find the probability density function (PDF) value at VaR
pdf_at_VaR = norm.pdf(VaR, loc=portfolio_loss_distribution, scale=portfolio_loss_std_dev)

# Then, we calculate the tail probability beyond VaR (1 - confidence level)
tail_probability = 1 - confidence_level

# Finally, we calculate the TVaR using the formula: VaR + (pdf_at_VaR / tail_probability)
TVaR = VaR + (pdf_at_VaR / tail_probability)

print("Tail Value at Risk (TVaR):", TVaR)
```

### **Tornado Risk of Arkansas Real Estate properties**

![image info](/assets/images/arkansas_risk_realestate.png)<img src="/assets/images/legend.png"  width="80" height="100">
- ***The map above shows real estate properties that have encountered at least 1 tornado (up to 7) in a 90-year period.***  
- ***Black symbols show real estate that has not encountered an tornado.***


* The map above shows real estate most at-risk to tornados, shown in yellow.
* Real Estate bought or owned, will incur loss given it's geographic setting
* Below, we apply  high resolution annual probabilities into common equations performed by actuaries and underwriters.



![image info](/assets/images/arkansas_risk_stats.png)

* we look up each property and return a precise tornado probability score
* `annual_probability` has a *geographic precision* of **110m^2**
* basis for the `expected_annual_loss` equation



### **Workflow: Process**

1. Ingest Tornado data public **REST API** service and stage in **PostgreSQL**
   1. Query API; paginate
   2. Store as GeoDataFrame
   3. Write to PostGIS
   4. Buffer geometry by 0.25 mile
2. Stage **Uber H3** hexagon layers in PostgreSQL by US state
     1. Loop through each state and create individual table name `{us_state}_h3`
3. Run an spatial intersection using **PostGIS** functions
      1. Loop through each state and perform spatial join between tornado buffer geometry and H3.
4. Dissolve by the `h3_id` to aggregate statistics into each H3 cell
5. **Summarize statistics** in a list array
6.  Join each state into one layer
7.  Write to PostgresSQL

We use Uber H3 hexagons to aggregate our geographic data together.  We use H3 because it:
-  allows a standard geometry (that is immutable, or never changes its shape) to aggregate data to
-  because it makes geography a controlled variable in ML/AI pipelines.  
  
This allows data and computer vision scientists to easily assess geographic and non-geographic variables when fitting and explaining predictive analytics.


**Reference:**

Rejda, G. E., & McNamara, M. J. (2021). Principles of Risk Management and Insurance (14th ed.). Pearson.